{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7151fcda",
   "metadata": {},
   "source": [
    "## Modelo de Detecção de Modelos de Detecção de Smishing\n",
    "\n",
    "Ankit Kumar Jain, B.B. Gupta,\n",
    "Rule-Based Framework for Detection of Smishing Messages in Mobile Environment,\n",
    "Procedia Computer Science,\n",
    "Volume 125,\n",
    "2018,\n",
    "Pages 617-623,\n",
    "ISSN 1877-0509,\n",
    "https://doi.org/10.1016/j.procs.2017.12.079.\n",
    "(https://www.sciencedirect.com/science/article/pii/S1877050917328478)\n",
    "Abstract: Smishing is a cyber-security attack, which utilizes Short Message Service (SMS) to steal personal credentials of mobile users. The trust level of users on their smart devices has attracted attackers for performing various mobile security attacks like Smishing. In this paper, we implement the rule-based data mining classification approach in the detection of smishing messages. The proposed approach identified nine rules which can efficiently filter smishing SMS from the genuine one. Further, our approach applies rule-based classification algorithms to train these outstanding rules. Since the SMS text messages are very short and generally written in Lingo language, we have used text normalization to convert them into standard form to obtain better rules. The performance of the proposed approach is evaluated, and it achieved more than 99% true negative rate. Furthermore, the proposed approach is very efficient for the detection of the zero hour attack too.\n",
    "Keywords: Smishing; Mobile Phishing; Data mining; Short messaging service; Machine learning\n",
    "\n",
    "> Reprodução de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71268bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75896f",
   "metadata": {},
   "source": [
    "#### 1. Pré processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08546b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ca51d266-5db5-4715-84c8-7ad4cfe3f991",
       "rows": [
        [
         "0",
         "ham",
         "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat..."
        ],
        [
         "1",
         "ham",
         "Ok lar... Joking wif u oni..."
        ],
        [
         "2",
         "spam",
         "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's"
        ],
        [
         "3",
         "ham",
         "U dun say so early hor... U c already then say..."
        ],
        [
         "4",
         "ham",
         "Nah I don't think he goes to usf, he lives around here though"
        ],
        [
         "5",
         "spam",
         "FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv"
        ],
        [
         "6",
         "ham",
         "Even my brother is not like to speak with me. They treat me like aids patent."
        ],
        [
         "7",
         "ham",
         "As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune"
        ],
        [
         "8",
         "spam",
         "WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only."
        ],
        [
         "9",
         "spam",
         "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030"
        ],
        [
         "10",
         "ham",
         "I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today."
        ],
        [
         "11",
         "spam",
         "SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info"
        ],
        [
         "12",
         "spam",
         "URGENT! You have won a 1 week FREE membership in our å£100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18"
        ],
        [
         "13",
         "ham",
         "I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times."
        ],
        [
         "14",
         "ham",
         "I HAVE A DATE ON SUNDAY WITH WILL!!"
        ],
        [
         "15",
         "spam",
         "XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL"
        ],
        [
         "16",
         "ham",
         "Oh k...i'm watching here:)"
        ],
        [
         "17",
         "ham",
         "Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet."
        ],
        [
         "18",
         "ham",
         "Fine if thatåÕs the way u feel. ThatåÕs the way its gota b"
        ],
        [
         "19",
         "spam",
         "England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/Ì¼1.20 POBOXox36504W45WQ 16+"
        ],
        [
         "20",
         "ham",
         "Is that seriously how you spell his name?"
        ],
        [
         "21",
         "ham",
         "IÛ÷m going to try for 2 months ha ha only joking"
        ],
        [
         "22",
         "ham",
         "So Ì_ pay first lar... Then when is da stock comin..."
        ],
        [
         "23",
         "ham",
         "Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already?"
        ],
        [
         "24",
         "ham",
         "Ffffffffff. Alright no way I can meet up with you sooner?"
        ],
        [
         "25",
         "ham",
         "Just forced myself to eat a slice. I'm really not hungry tho. This sucks. Mark is getting worried. He knows I'm sick when I turn down pizza. Lol"
        ],
        [
         "26",
         "ham",
         "Lol your always so convincing."
        ],
        [
         "27",
         "ham",
         "Did you catch the bus ? Are you frying an egg ? Did you make a tea? Are you eating your mom's left over dinner ? Do you feel my Love ?"
        ],
        [
         "28",
         "ham",
         "I'm back &amp; we're packing the car now, I'll let you know if there's room"
        ],
        [
         "29",
         "ham",
         "Ahhh. Work. I vaguely remember that! What does it feel like? Lol"
        ],
        [
         "30",
         "ham",
         "Wait that's still not all that clear, were you not sure about me being sarcastic or that that's why x doesn't want to live with us"
        ],
        [
         "31",
         "ham",
         "Yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and he got caught up in that. Till 2! But we won't go there! Not doing too badly cheers. You? "
        ],
        [
         "32",
         "ham",
         "K tell me anything about you."
        ],
        [
         "33",
         "ham",
         "For fear of fainting with the of all that housework you just did? Quick have a cuppa"
        ],
        [
         "34",
         "spam",
         "Thanks for your subscription to Ringtone UK your mobile will be charged å£5/month Please confirm by replying YES or NO. If you reply NO you will not be charged"
        ],
        [
         "35",
         "ham",
         "Yup... Ok i go home look at the timings then i msg Ì_ again... Xuhui going to learn on 2nd may too but her lesson is at 8am"
        ],
        [
         "36",
         "ham",
         "Oops, I'll let you know when my roommate's done"
        ],
        [
         "37",
         "ham",
         "I see the letter B on my car"
        ],
        [
         "38",
         "ham",
         "Anything lor... U decide..."
        ],
        [
         "39",
         "ham",
         "Hello! How's you and how did saturday go? I was just texting to see if you'd decided to do anything tomo. Not that i'm trying to invite myself or anything!"
        ],
        [
         "40",
         "ham",
         "Pls go ahead with watts. I just wanted to be sure. Do have a great weekend. Abiola"
        ],
        [
         "41",
         "ham",
         "Did I forget to tell you ? I want you , I need you, I crave you ... But most of all ... I love you my sweet Arabian steed ... Mmmmmm ... Yummy"
        ],
        [
         "42",
         "spam",
         "07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow"
        ],
        [
         "43",
         "ham",
         "WHO ARE YOU SEEING?"
        ],
        [
         "44",
         "ham",
         "Great! I hope you like your man well endowed. I am  &lt;#&gt;  inches..."
        ],
        [
         "45",
         "ham",
         "No calls..messages..missed calls"
        ],
        [
         "46",
         "ham",
         "Didn't you get hep b immunisation in nigeria."
        ],
        [
         "47",
         "ham",
         "Fair enough, anything going on?"
        ],
        [
         "48",
         "ham",
         "Yeah hopefully, if tyler can't do it I could maybe ask around a bit"
        ],
        [
         "49",
         "ham",
         "U don't know how stubborn I am. I didn't even want to go to the hospital. I kept telling Mark I'm not a weak sucker. Hospitals are for weak suckers."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5572
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the CSV dataset as a dataframe\n",
    "# Since pandas is already imported in cell 1, we can use it directly\n",
    "df = pandas.read_csv('SMSSpamCollectionDataset.csv', encoding='latin-1')\n",
    "df = df[['label', 'text']]\n",
    "\n",
    "# Display the first few rows to get a glimpse of the data\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "299f844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005!\n",
      "Normalizado: free entry wkly comp win cup final tkts 21st may 2005 !\n"
     ]
    }
   ],
   "source": [
    "# Download dos recursos necessários do NLTK\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True) \n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "def normalize_text(original_text) -> str:\n",
    "    '''\n",
    "    Recebe um SMS\n",
    "    \n",
    "    Retorna texto original normalizado (mais conservador para melhor performance)\n",
    "    '''\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = original_text.lower()\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Tokenize (método mais simples se houver problemas com punkt)\n",
    "    try:\n",
    "        words = nltk.word_tokenize(text)\n",
    "    except:\n",
    "        # Fallback para tokenização simples\n",
    "        words = text.split()\n",
    "    \n",
    "    # Remove stopwords apenas as mais comuns (mais conservador)\n",
    "    # IMPORTANTE: Preservar símbolos financeiros e matemáticos mesmo que sejam curtos\n",
    "    common_stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should'}\n",
    "    \n",
    "    # Símbolos financeiros e matemáticos importantes para detecção de spam/smishing\n",
    "    important_symbols = {\n",
    "        # Símbolos financeiros\n",
    "        '$', '£', '€', '¥', '₹', '¢', \n",
    "        # Símbolos matemáticos\n",
    "        '+', '-', '*', '/', '=', '<', '>', '≤', '≥', '≠', '±', '×', '÷',\n",
    "        # Outros símbolos importantes  \n",
    "        '%', '#', '@', '&', '!', '?'\n",
    "    }\n",
    "    \n",
    "    # Manter palavra se: não é stopword E (tem mais de 1 char OU é símbolo importante)\n",
    "    words = [word for word in words if word not in common_stopwords and (len(word) > 1 or word in important_symbols)]\n",
    "    \n",
    "    # NÃO aplicar stemming agressivo - manter palavras mais íntegras\n",
    "    # Preservar símbolos importantes e palavras relevantes\n",
    "    words = [word for word in words if len(word) > 2 or word in important_symbols]\n",
    "    \n",
    "    # Join words back into a string\n",
    "    normalized_text = ' '.join(words)\n",
    "    \n",
    "    return normalized_text\n",
    "\n",
    "# Testar com um exemplo\n",
    "sample_text = \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005!\"\n",
    "print(f\"Original: {sample_text}\")\n",
    "print(f\"Normalizado: {normalize_text(sample_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0678b",
   "metadata": {},
   "source": [
    "(debugando o por quê do símbolo de dolar estar sumindo e verificando que ainda funciona...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b4606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Original: 'Get $500 bonus!'\n",
      "2. Lowercase: 'get $500 bonus!'\n",
      "3. Remove spaces: 'get $500 bonus!'\n",
      "4. NLTK tokenize: ['get', '$', '500', 'bonus', '!']\n",
      "5. After stopwords removal: ['get', '$', '500', 'bonus', '!']\n",
      "6. After length filter (>2): ['get', '$', '500', 'bonus', '!']\n",
      "7. Final result: 'get $ 500 bonus !'\n",
      "--------------------------------------------------\n",
      "1. Original: 'Only $19.99 today!'\n",
      "2. Lowercase: 'only $19.99 today!'\n",
      "3. Remove spaces: 'only $19.99 today!'\n",
      "4. NLTK tokenize: ['only', '$', '19.99', 'today', '!']\n",
      "5. After stopwords removal: ['only', '$', '19.99', 'today', '!']\n",
      "6. After length filter (>2): ['only', '$', '19.99', 'today', '!']\n",
      "7. Final result: 'only $ 19.99 today !'\n",
      "--------------------------------------------------\n",
      "1. Original: 'Win £1000 prize!'\n",
      "2. Lowercase: 'win £1000 prize!'\n",
      "3. Remove spaces: 'win £1000 prize!'\n",
      "4. NLTK tokenize: ['win', '£1000', 'prize', '!']\n",
      "5. After stopwords removal: ['win', '£1000', 'prize', '!']\n",
      "6. After length filter (>2): ['win', '£1000', 'prize', '!']\n",
      "7. Final result: 'win £1000 prize !'\n",
      "--------------------------------------------------\n",
      "1. Original: 'Cost €250 only'\n",
      "2. Lowercase: 'cost €250 only'\n",
      "3. Remove spaces: 'cost €250 only'\n",
      "4. NLTK tokenize: ['cost', '€250', 'only']\n",
      "5. After stopwords removal: ['cost', '€250', 'only']\n",
      "6. After length filter (>2): ['cost', '€250', 'only']\n",
      "7. Final result: 'cost €250 only'\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: Vamos rastrear passo a passo onde o $ está sendo perdido\n",
    "def debug_normalize_text(original_text):\n",
    "    print(f\"1. Original: '{original_text}'\")\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = original_text.lower()\n",
    "    print(f\"2. Lowercase: '{text}'\")\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    print(f\"3. Remove spaces: '{text}'\")\n",
    "    \n",
    "    # Tokenize\n",
    "    try:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        print(f\"4. NLTK tokenize: {words}\")\n",
    "    except:\n",
    "        words = text.split()\n",
    "        print(f\"4. Simple split: {words}\")\n",
    "    \n",
    "    # Remove stopwords\n",
    "    common_stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should'}\n",
    "    important_symbols = {\n",
    "        # Símbolos financeiros\n",
    "        '$', '£', '€', '¥', '₹', '¢', \n",
    "        # Símbolos matemáticos\n",
    "        '+', '-', '*', '/', '=', '<', '>', '≤', '≥', '≠', '±', '×', '÷',\n",
    "        # Outros símbolos importantes  \n",
    "        '%', '#', '@', '&', '!', '?'\n",
    "    }\n",
    "    \n",
    "    # Manter palavra se: não é stopword E (tem mais de 1 char OU é símbolo importante)\n",
    "    words_after_stopwords = [word for word in words if word not in common_stopwords and (len(word) > 1 or word in important_symbols)]\n",
    "    print(f\"5. After stopwords removal: {words_after_stopwords}\")\n",
    "    \n",
    "    # Remove short words mas preserva símbolos importantes\n",
    "    words_after_length = [word for word in words_after_stopwords if len(word) > 2 or word in important_symbols]\n",
    "    print(f\"6. After length filter (>2): {words_after_length}\")\n",
    "    \n",
    "    result = ' '.join(words_after_length)\n",
    "    print(f\"7. Final result: '{result}'\")\n",
    "    print(\"-\" * 50)\n",
    "    return result\n",
    "\n",
    "# Testar com exemplos problemáticos\n",
    "test_cases = [\n",
    "    \"Get $500 bonus!\",\n",
    "    \"Only $19.99 today!\",\n",
    "    \"Win £1000 prize!\",\n",
    "    \"Cost €250 only\"\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    debug_normalize_text(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbbc8bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTE COM SÍMBOLOS MATEMÁTICOS E FINANCEIROS ===\n",
      "\n",
      "1. Original: Get $500 + 20% bonus = $600 total!\n",
      "   Normalizado: get $ 500 + % bonus = $ 600 total !\n",
      "   Símbolos preservados: $(financial), +(mathematical), =(mathematical), %(other), !(other)\n",
      "\n",
      "2. Original: Discount: 50% - 10% = 40% off today!\n",
      "   Normalizado: discount % - % = % off today !\n",
      "   Símbolos preservados: -(mathematical), =(mathematical), %(other), !(other)\n",
      "\n",
      "3. Original: Calculate: 2 + 2 = 4, 10 * 5 = 50\n",
      "   Normalizado: calculate + = * =\n",
      "   Símbolos preservados: +(mathematical), *(mathematical), =(mathematical)\n",
      "\n",
      "4. Original: Price: £100 > £80 (save £20!)\n",
      "   Normalizado: price £100 > £80 save £20 !\n",
      "   Símbolos preservados: £(financial), >(mathematical), !(other)\n",
      "\n",
      "5. Original: Rate: 5% < 10% but > 2%\n",
      "   Normalizado: rate % < % > %\n",
      "   Símbolos preservados: <(mathematical), >(mathematical), %(other)\n",
      "\n",
      "6. Original: Win €250 × 2 = €500 prize!\n",
      "   Normalizado: win €250 × = €500 prize !\n",
      "   Símbolos preservados: €(financial), =(mathematical), ×(mathematical), !(other)\n",
      "\n",
      "7. Original: Cost: $19.99 ÷ 2 = $9.99 each\n",
      "   Normalizado: cost $ 19.99 ÷ = $ 9.99 each\n",
      "   Símbolos preservados: $(financial), =(mathematical), ÷(mathematical)\n"
     ]
    }
   ],
   "source": [
    "# Testar com exemplos que contêm símbolos matemáticos e financeiros\n",
    "math_test_cases = [\n",
    "    \"Get $500 + 20% bonus = $600 total!\",\n",
    "    \"Discount: 50% - 10% = 40% off today!\",\n",
    "    \"Calculate: 2 + 2 = 4, 10 * 5 = 50\",\n",
    "    \"Price: £100 > £80 (save £20!)\",\n",
    "    \"Rate: 5% < 10% but > 2%\",\n",
    "    \"Win €250 × 2 = €500 prize!\",\n",
    "    \"Cost: $19.99 ÷ 2 = $9.99 each\"\n",
    "]\n",
    "\n",
    "print(\"=== TESTE COM SÍMBOLOS MATEMÁTICOS E FINANCEIROS ===\")\n",
    "for i, text in enumerate(math_test_cases, 1):\n",
    "    normalized = normalize_text(text)\n",
    "    print(f\"\\n{i}. Original: {text}\")\n",
    "    print(f\"   Normalizado: {normalized}\")\n",
    "    \n",
    "    # Verificar se símbolos importantes foram preservados\n",
    "    important_symbols_in_text = {\n",
    "        'financial': ['$', '£', '€', '¥', '₹', '¢'],\n",
    "        'mathematical': ['+', '-', '*', '/', '=', '<', '>', '≤', '≥', '≠', '±', '×', '÷'],\n",
    "        'other': ['%', '#', '@', '&', '!', '?']\n",
    "    }\n",
    "    \n",
    "    found_symbols = []\n",
    "    for category, symbols in important_symbols_in_text.items():\n",
    "        for sym in symbols:\n",
    "            if sym in text and sym in normalized:\n",
    "                found_symbols.append(f\"{sym}({category})\")\n",
    "            elif sym in text and sym not in normalized:\n",
    "                found_symbols.append(f\"❌{sym}({category})\")\n",
    "    \n",
    "    if found_symbols:\n",
    "        print(f\"   Símbolos preservados: {', '.join(found_symbols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4e3cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Go until jurong point, crazy.. Available only ...   \n",
      "1                      Ok lar... Joking wif u oni...   \n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3  U dun say so early hor... U c already then say...   \n",
      "4  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                     normalized_text  \n",
      "0  until jurong point crazy available only bugis ...  \n",
      "1                         lar ... joking wif oni ...  \n",
      "2  free entry wkly comp win cup final tkts 21st m...  \n",
      "3         dun say early hor ... already then say ...  \n",
      "4    nah n't think goes usf lives around here though  \n"
     ]
    }
   ],
   "source": [
    "# Apply the normalize_text function to the text column\n",
    "df['normalized_text'] = df['text'].apply(normalize_text)\n",
    "\n",
    "# Display the first few rows to see the normalized text\n",
    "print(df[['text', 'normalized_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae67821",
   "metadata": {},
   "source": [
    "### 2. Extração de features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da21de2",
   "metadata": {},
   "source": [
    "#### 2.1 Existência de links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule1(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Checks if a text contains a URL/link.\n",
    "    Returns 1 if a URL is found, 0 otherwise.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text to check for URLs\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if URL is found, 0 otherwise\n",
    "    \"\"\"\n",
    "    # Comprehensive URL pattern to catch various formats\n",
    "    # Including common TLDs, shortened URLs, and URLs without protocol\n",
    "    url_pattern = re.compile(r'''\n",
    "        (https?://)?                               # Optional protocol (http:// or https://)\n",
    "        (www\\.)?                                   # Optional www\n",
    "        ([a-zA-Z0-9-]+\\.)+                         # Domain name parts\n",
    "        ([a-zA-Z]{2,63})                           # Top-level domain\n",
    "        (/\\S*)?                                    # Optional path\n",
    "        |                                          # OR shortened URLs\n",
    "        (bit\\.ly|t\\.co|goo\\.gl|tinyurl\\.com)/\\S*  # Common URL shorteners\n",
    "    ''', re.VERBOSE)\n",
    "    \n",
    "    # Check if the pattern is found in the text\n",
    "    if url_pattern.search(text):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ffb1da",
   "metadata": {},
   "source": [
    "#### 2.2 Existência de símbolos matemáticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0808f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule2(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Checks if a text contains any mathematical symbols.\n",
    "    Returns 1 if any mathematical symbol is found, 0 otherwise.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text to check for mathematical symbols\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if mathematical symbols are found, 0 otherwise\n",
    "    \"\"\"\n",
    "    # Define a comprehensive set of mathematical symbols\n",
    "    math_symbols = {\n",
    "        # Basic arithmetic\n",
    "        '+', '-', '*', '/', '=', \n",
    "        # Comparison\n",
    "        '<', '>', '≤', '≥', '≠',\n",
    "        # Other math symbols\n",
    "        '±', '×', '÷', '∑', '∏', '√', '∛', \n",
    "        # Superscripts and subscripts commonly used in math\n",
    "        '²', '³', '¹', '½', '¼', '¾',\n",
    "        # Greek letters often used in mathematics\n",
    "        'π', 'θ', 'Δ', 'Σ', 'Ω',\n",
    "        # Other math-related symbols\n",
    "        '∞', '∫', '∂', '∇', '∀', '∃', '∈', '∉', '∩', '∪'\n",
    "    }\n",
    "    \n",
    "    # Check if any mathematical symbol is found in the text\n",
    "    for symbol in math_symbols:\n",
    "        if symbol in text:\n",
    "            return 1\n",
    "    \n",
    "    # Also check for numeric expressions with operators using regex\n",
    "    # This catches patterns like \"2+2\", \"5*10\", \"100/2\" etc.\n",
    "    math_expression_pattern = re.compile(r'\\d+\\s*[+\\-*/=]\\s*\\d+')\n",
    "    if math_expression_pattern.search(text):\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84caafed",
   "metadata": {},
   "source": [
    "#### 2.3 Existência de símbolos financeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule3(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Checks if a text contains any financial symbols.\n",
    "    Returns 1 if any financial symbol is found, 0 otherwise.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text to check for financial symbols\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if financial symbols are found, 0 otherwise\n",
    "    \"\"\"\n",
    "    # Define common financial symbols\n",
    "    financial_symbols = ['$', '£', '€', '¥', '₹', '¢']\n",
    "    \n",
    "    # Check if any financial symbol is in the text\n",
    "    for symbol in financial_symbols:\n",
    "        if symbol in text:\n",
    "            return 1\n",
    "    \n",
    "    # Check for currency codes and financial terms using regex\n",
    "    financial_patterns = [\n",
    "        r'\\b(USD|EUR|GBP|JPY|AUD|CAD|CHF|CNY|INR)\\b',  # Common currency codes | ADICIONAR O REAL\n",
    "        r'\\b(dollar|euro|pound|yen|rupee|cent)[s]?\\b',  # Currency names\n",
    "        r'\\b\\d+(\\.\\d+)?\\s*(dollars?|euros?|pounds?|yens?|rupees?)\\b',  # Amount with currency name\n",
    "        # r'\\bmoney\\s+back\\b',  # Common financial phrases\n",
    "        # r'\\bcash\\s+prize[s]?\\b',\n",
    "        # r'\\bfree\\s+cash\\b'\n",
    "    ]\n",
    "    \n",
    "    for pattern in financial_patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57842d2c",
   "metadata": {},
   "source": [
    "#### 2.4 Existência de número de celular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503600f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule4(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Checks if a text contains a mobile phone number.\n",
    "    Returns 1 if a phone number is found, 0 otherwise.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text to check for phone numbers\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if phone number is found, 0 otherwise\n",
    "    \"\"\"\n",
    "    # Various phone number patterns to match different formats\n",
    "    phone_patterns = [\n",
    "        # International format with country code (e.g., +1 123 456 7890, +44-7911-123456)\n",
    "        r'(?:\\+\\d{1,3}[-\\.\\s]?)?\\(?\\d{1,4}\\)?[-\\.\\s]?\\d{1,4}[-\\.\\s]?\\d{1,9}',\n",
    "        \n",
    "        # US/Canada format (e.g., (123) 456-7890, 123-456-7890)\n",
    "        r'\\(?\\d{3}\\)?[-\\.\\s]?\\d{3}[-\\.\\s]?\\d{4}',\n",
    "        \n",
    "        # UK format (e.g., 07911 123456, 07911-123-456)\n",
    "        r'0\\d{3}[-\\.\\s]?\\d{3}[-\\.\\s]?\\d{3,4}',\n",
    "        \n",
    "        # Generic formats with at least 10 digits\n",
    "        r'\\b\\d{3}[-\\.\\s]?\\d{3}[-\\.\\s]?\\d{4}\\b',\n",
    "        \n",
    "        # Format with separators (e.g., 123.456.7890)\n",
    "        r'\\d{3}[.\\-]\\d{3}[.\\-]\\d{4}',\n",
    "        \n",
    "        # Simple sequence of digits (e.g., 1234567890) - at least 10 digits but not more than 15\n",
    "        r'\\b\\d{10,15}\\b'\n",
    "    ]\n",
    "    \n",
    "    # Check if any pattern matches the text\n",
    "    for pattern in phone_patterns:\n",
    "        if re.search(pattern, text):\n",
    "            return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f455301",
   "metadata": {},
   "source": [
    "#### 2.5 Existência de palavras suspeitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e30e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule5(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Checks if a text contains suspicious words commonly used in scam or phishing messages.\n",
    "    Returns 1 if any suspicious word is found, 0 otherwise.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text to check for suspicious words\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if suspicious words are found, 0 otherwise\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Define suspicious word patterns by category\n",
    "    suspicious_patterns = {\n",
    "        # Financial incentives\n",
    "        'financial': [\n",
    "            r'\\bfree\\b', r'\\bwin\\b', r'\\bwon\\b', r'\\bprize[s]?\\b', r'\\bcash\\b', r'\\bmoney\\b', \n",
    "            r'\\bgift[s]?\\b', r'\\bdiscount\\b', r'\\bbonus\\b', r'\\bclaim\\b', r'\\breward[s]?\\b', \n",
    "            r'\\bcredit[s]?\\b', r'\\brefund\\b', r'\\b\\d+%\\s+off\\b', r'\\bsave\\s+\\d+\\b'\n",
    "        ],\n",
    "        \n",
    "        # Urgency words\n",
    "        'urgency': [\n",
    "            r'\\burgent\\b', r'\\bimmediate\\b', r'\\bquick\\b', r'\\blast\\s+chance\\b', \n",
    "            r'\\blimited\\s+time\\b', r'\\bexpires?\\b', r'\\bexpiring\\b', r'\\btoday\\s+only\\b', \n",
    "            r'\\bact\\s+now\\b', r'\\bhurry\\b', r'\\bdeadline\\b', r'\\btomorrow\\b'\n",
    "        ],\n",
    "        \n",
    "        # Account-related\n",
    "        'account': [\n",
    "            r'\\baccount[s]?\\b', r'\\bpassword[s]?\\b', r'\\blogin\\b', r'\\bverify\\b', r'\\bsecurity\\b', \n",
    "            r'\\bupdate[s]?\\b', r'\\bconfirm\\b', r'\\bvalidate\\b', r'\\bauthenticate\\b', r'\\breset\\b', \n",
    "            r'\\bsuspended\\b', r'\\block[ed]?\\b', r'\\bdeactivate[d]?\\b', r'\\breactivate\\b'\n",
    "        ],\n",
    "        \n",
    "        # Official-sounding terms\n",
    "        'official': [\n",
    "            r'\\bnotice\\b', r'\\balert[s]?\\b', r'\\bwarning[s]?\\b', r'\\bimportant\\b', r'\\bofficial\\b', \n",
    "            r'\\blegal\\b', r'\\bgovernment\\b', r'\\bbank\\b', r'\\btax[es]?\\b', r'\\bcompensation\\b',\n",
    "            r'\\bauthority\\b', r'\\bagency\\b', r'\\bdepartment\\b', r'\\bpayment[s]?\\b'\n",
    "        ],\n",
    "        \n",
    "        # Call to action\n",
    "        'action': [\n",
    "            r'\\bclick\\b', r'\\bfollow\\b', r'\\bcall\\b', r'\\bregister\\b', r'\\bsubscribe\\b', r'\\bapply\\b',\n",
    "            r'\\bdownload\\b', r'\\bsubmit\\b', r'\\breply\\b', r'\\brespond\\b', r'\\bcomplete\\b', r'\\bvisit\\b',\n",
    "            r'\\bcheck\\b', r'\\blink\\b', r'\\burl\\b', r'\\bwebsite\\b', r'\\binfo[rmation]?\\b'\n",
    "        ],\n",
    "        \n",
    "        # Pressure tactics\n",
    "        'pressure': [\n",
    "            r'\\bonly\\b', r'\\bselected\\b', r'\\bchosen\\b', r'\\bexclusive\\b', r'\\bspecial\\b',\n",
    "            r'\\blucky\\b', r'\\bchance\\b', r'\\bopportunity\\b', r'\\brisk\\b', r'\\bproblem\\b',\n",
    "            r'\\bnow\\b', r'\\btoday\\b', r'\\blast\\b', r'\\bone\\s+time\\b', r'\\bfinal\\b'\n",
    "        ],\n",
    "        \n",
    "        # Common scam phrases\n",
    "        'scam_phrases': [\n",
    "            r'\\byou\\s+have\\s+won\\b', r'\\bcongratulations\\b', r'\\blottery\\b', r'\\bprize\\s+draw\\b',\n",
    "            r'\\bunclaimed\\b', r'\\bunique\\s+offer\\b', r'\\bexclusive\\s+deal\\b', r'\\bverify\\s+your\\s+identity\\b',\n",
    "            r'\\baccess\\s+denied\\b', r'\\baccount\\s+suspended\\b', r'\\bsecurity\\s+breach\\b',\n",
    "            r'\\blimited\\s+offer\\b', r'\\bfree\\s+money\\b', r'\\bguaranteed\\s+results\\b'\n",
    "        ],\n",
    "\n",
    "        # Common scam phrases from paper\n",
    "        'paper_phrases': [\n",
    "            r'\\bfree\\b', r'\\baccident\\b', r'\\bawards\\b', r'\\bdating\\b', r'\\bwon\\b', r'\\bservice\\b',\n",
    "            r'\\blottery\\b',r'\\bmins\\b',r'\\bfree\\b',r'\\bvisit\\b',r'\\bdelivery\\b',r'\\bcash\\b',r'\\bclaim\\b',r'\\bprize\\b',\n",
    "            r'\\bdelivery\\b'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Check for suspicious patterns in text\n",
    "    for category, patterns in suspicious_patterns.items():\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, text_lower):\n",
    "                return 1\n",
    "    \n",
    "    # Look for combinations of suspicious elements\n",
    "    # These are more indicative when found together\n",
    "    combinations = [\n",
    "        # Urgency + financial\n",
    "        (r'\\b(urgent|quick|hurry|now)\\b.*\\b(free|money|cash|prize|win)\\b', \n",
    "         r'\\b(free|money|cash|prize|win)\\b.*\\b(urgent|quick|hurry|now)\\b'),\n",
    "         \n",
    "        # Action + account\n",
    "        (r'\\b(click|call|reply)\\b.*\\b(account|password|login|verify)\\b',\n",
    "         r'\\b(account|password|login|verify)\\b.*\\b(click|call|reply)\\b'),\n",
    "         \n",
    "        # Financial + pressure\n",
    "        (r'\\b(money|cash|free|win)\\b.*\\b(only|exclusive|special|chance)\\b',\n",
    "         r'\\b(only|exclusive|special|chance)\\b.*\\b(money|cash|free|win)\\b')\n",
    "    ]\n",
    "    \n",
    "    for pair in combinations:\n",
    "        if re.search(pair[0], text_lower) or re.search(pair[1], text_lower):\n",
    "            return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a544a",
   "metadata": {},
   "source": [
    "#### 2.6 Mensagem muito grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule6(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Checks if a text message is longer than a threshold length.\n",
    "    Returns 1 if the message is considered too long, 0 otherwise.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text to check for length\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if text is too long, 0 otherwise\n",
    "    \"\"\"\n",
    "    # Define threshold for message length (150 characters)\n",
    "    # SMS smishing attempts often use longer messages to make sophisticated scams\n",
    "    threshold_length = 150\n",
    "    \n",
    "    # Check if the message length exceeds the threshold\n",
    "    if len(text) > threshold_length:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73ec297",
   "metadata": {},
   "source": [
    "#### 2.7 Existência de self-answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0712e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule7(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Checks if a text contains self-answering patterns, which are common in smishing attempts.\n",
    "    These patterns include text that asks a question and immediately provides an answer,\n",
    "    or uses rhetorical questions to manipulate the recipient.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text to check for self-answering patterns\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if self-answering patterns are found, 0 otherwise\n",
    "    \"\"\"\n",
    "    # Convert to lowercase for case-insensitive matching\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Define patterns for self-answering techniques\n",
    "    self_answering_patterns = [\n",
    "        # Question followed by immediate answer\n",
    "        r'\\b(did you|have you|are you|would you|could you|do you).*\\?\\s*yes',\n",
    "        r'\\b(did you|have you|are you|would you|could you|do you).*\\?\\s*no',\n",
    "        \n",
    "        # Rhetorical questions used to lead recipient\n",
    "        r'(want to|looking to|interested in|need to).*\\?',\n",
    "        r'(wondering|curious|thinking) (about|if|whether).*\\?',\n",
    "        \n",
    "        # False choices - presenting limited options\n",
    "        r'(reply|text|send) (yes|no|y|n|1|2|stop|start)',\n",
    "        r'choose (between|from)',\n",
    "        \n",
    "        # Self-answering statements\n",
    "        r'you\\'re (probably|likely|surely) (wondering|asking|thinking)',\n",
    "        r'i know (you|what you|that you)',\n",
    "        \n",
    "        # False assumptions that imply consent\n",
    "        r'as (requested|you asked|you wanted)',\n",
    "        r'(per|following|based on) your (request|inquiry|interest)',\n",
    "        \n",
    "        # Leading questions with implied answers\n",
    "        r'who (doesn\\'t|wouldn\\'t) want',\n",
    "        r'isn\\'t it time',\n",
    "        r'why not',\n",
    "        \n",
    "        # Fake response requirements\n",
    "        r'(text|reply|send|call|sms) \\w+ to (claim|get|receive|stop|confirm)'\n",
    "    ]\n",
    "    \n",
    "    # Check if any of the patterns exist in the text\n",
    "    for pattern in self_answering_patterns:\n",
    "        if re.search(pattern, text_lower):\n",
    "            return 1\n",
    "    \n",
    "    # Look for question-answer pairs (question mark followed by answer)\n",
    "    question_answer_pattern = r'\\?[^?!.]{1,30}(yes|no|absolutely|definitely|of course|sure|certainly)'\n",
    "    if re.search(question_answer_pattern, text_lower):\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75fcf7",
   "metadata": {},
   "source": [
    "### 2.8 Existência de \"visual morphemes\" (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd36d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule8(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Checks if a text contains visual morphemes - characters, symbols, or formatting \n",
    "    that can be used to visually mislead recipients in smishing attacks.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text to check for visual morphemes\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if visual morphemes are found, 0 otherwise\n",
    "    \"\"\"\n",
    "    # Convert to lowercase for consistent pattern matching\n",
    "    # (but keep a copy of original text for case-based patterns)\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # 1. Check for excessive use of uppercase (shouting)\n",
    "    uppercase_ratio = sum(1 for c in text if c.isupper()) / len(text) if len(text) > 0 else 0\n",
    "    if uppercase_ratio > 0.3 and len(text) > 5:  # If more than 30% of characters are uppercase\n",
    "        return 1\n",
    "    \n",
    "    # 2. Check for repeated punctuation (emphasis or attention-grabbing)\n",
    "    repeated_punctuation_patterns = [\n",
    "        r'[!]{2,}',      # Multiple exclamation marks\n",
    "        r'[?]{2,}',      # Multiple question marks\n",
    "        r'[.]{3,}',      # Ellipsis with many dots\n",
    "        r'[!?]{2,}',     # Mixed exclamation and question marks\n",
    "        r'[$£€¥₹¢]{2,}'  # Repeated currency symbols\n",
    "    ]\n",
    "    \n",
    "    for pattern in repeated_punctuation_patterns:\n",
    "        if re.search(pattern, text):\n",
    "            return 1\n",
    "    \n",
    "    # 3. Check for unusual character substitution (l33t speak or similar)\n",
    "    substitution_patterns = [\n",
    "        r'\\b\\w*[0-9]+\\w*[a-zA-Z]+\\w*\\b',  # Numbers mixed with letters in a word\n",
    "        r'\\b\\w*[a-zA-Z]+\\w*[0-9]+\\w*\\b',  # Letters mixed with numbers in a word\n",
    "        r'\\b[a-zA-Z0-9]*[@$&*]+[a-zA-Z0-9]*\\b'  # Special characters embedded in words\n",
    "    ]\n",
    "    \n",
    "    for pattern in substitution_patterns:\n",
    "        if re.search(pattern, text) and not re.search(r'\\b(https?://|www\\.)\\S+', text):  # Exclude URLs\n",
    "            return 1\n",
    "    \n",
    "    # 4. Check for excessive spacing or formatting\n",
    "    spacing_patterns = [\n",
    "        r'(\\s{2,})',     # Multiple spaces\n",
    "        r'([_-]{2,})'    # Multiple underscores or hyphens used for formatting\n",
    "    ]\n",
    "    \n",
    "    for pattern in spacing_patterns:\n",
    "        if len(re.findall(pattern, text)) > 2:  # More than 2 instances of unusual spacing\n",
    "            return 1\n",
    "    \n",
    "    # 5. Check for unusual Unicode characters that mimic regular letters\n",
    "    # These are often used to bypass filters\n",
    "    suspicious_unicode_patterns = [\n",
    "        r'[\\u00A0-\\u00FF]',  # Latin-1 Supplement\n",
    "        r'[\\u0400-\\u04FF]',  # Cyrillic\n",
    "        r'[\\u0370-\\u03FF]',  # Greek\n",
    "        r'[\\u2000-\\u206F]',  # General Punctuation\n",
    "        r'[\\u2070-\\u209F]',  # Superscripts and Subscripts\n",
    "        r'[\\u20A0-\\u20CF]',  # Currency Symbols\n",
    "        r'[\\u2100-\\u214F]'   # Letterlike Symbols\n",
    "    ]\n",
    "    \n",
    "    # Only flag if there's a mix of ASCII and non-ASCII characters\n",
    "    has_ascii = bool(re.search(r'[a-zA-Z]', text))\n",
    "    has_suspicious_unicode = any(bool(re.search(pattern, text)) for pattern in suspicious_unicode_patterns)\n",
    "    \n",
    "    if has_ascii and has_suspicious_unicode:\n",
    "        return 1\n",
    "    \n",
    "    # 6. Check for patterns that create visual attention\n",
    "    visual_attention_patterns = [\n",
    "        r'(\\*\\*|\\*|\\#|\\=\\=|\\=){2,}[^*#=]+\\1{2,}',  # Text surrounded by asterisks or other markers\n",
    "        r'[A-Z]{3,}',                               # All caps words (3+ letters)\n",
    "        r'(?<!\\w)([A-Z][a-z]*){3,}(?!\\w)'          # CamelCase with 3+ words\n",
    "    ]\n",
    "    \n",
    "    for pattern in visual_attention_patterns:\n",
    "        if re.search(pattern, text):\n",
    "            return 1\n",
    "    \n",
    "    # 7. Check for excessive use of emojis or emoticons\n",
    "    emoji_patterns = [\n",
    "        r'(?::|;|=)(?:-)?(?:\\)|D|P|p|\\()',  # Basic emoticons\n",
    "        r'[\\U0001F600-\\U0001F64F]',         # Emoticons Unicode block\n",
    "        r'[\\U0001F300-\\U0001F5FF]',         # Miscellaneous Symbols and Pictographs\n",
    "        r'[\\U0001F680-\\U0001F6FF]',         # Transport and Map Symbols\n",
    "        r'[\\U0001F700-\\U0001F77F]',         # Alchemical Symbols\n",
    "        r'[\\U0001F780-\\U0001F7FF]',         # Geometric Shapes\n",
    "        r'[\\U0001F800-\\U0001F8FF]',         # Supplemental Arrows-C\n",
    "        r'[\\U0001F900-\\U0001F9FF]',         # Supplemental Symbols and Pictographs\n",
    "        r'[\\U0001FA00-\\U0001FA6F]'          # Chess Symbols\n",
    "    ]\n",
    "    \n",
    "    emoji_count = 0\n",
    "    for pattern in emoji_patterns:\n",
    "        emoji_count += len(re.findall(pattern, text))\n",
    "    \n",
    "    if emoji_count > 3:  # More than 3 emojis in a message\n",
    "        return 1\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacaadae",
   "metadata": {},
   "source": [
    "#### 2.9 Existência de e-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule9(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Checks if a text contains an email address.\n",
    "    Returns 1 if an email address is found, 0 otherwise.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text to check for email addresses\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if email address is found, 0 otherwise\n",
    "    \"\"\"\n",
    "    # Comprehensive email pattern to catch various formats\n",
    "    # This pattern supports:\n",
    "    # - Standard emails (user@domain.com)\n",
    "    # - Emails with numbers in username or domain\n",
    "    # - Emails with dots, underscores, hyphens, and plus signs in username\n",
    "    # - Various TLDs (com, net, org, edu, etc.)\n",
    "    # - Subdomains\n",
    "    \n",
    "    email_pattern = re.compile(r'''\n",
    "        \\b[a-zA-Z0-9._%+-]+            # Username part\n",
    "        @                              # @ symbol\n",
    "        [a-zA-Z0-9.-]+                 # Domain name\n",
    "        \\.[a-zA-Z]{2,63}               # TLD (.com, .org, etc.)\n",
    "        \\b\n",
    "    ''', re.VERBOSE)\n",
    "    \n",
    "    # Check if the pattern is found in the text\n",
    "    if email_pattern.search(text):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
