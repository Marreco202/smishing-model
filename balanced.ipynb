{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7151fcda",
   "metadata": {},
   "source": [
    "## Modelo de Detecção de Modelos de Detecção de Smishing\n",
    "\n",
    "Ankit Kumar Jain, B.B. Gupta,\n",
    "Rule-Based Framework for Detection of Smishing Messages in Mobile Environment,\n",
    "Procedia Computer Science,\n",
    "Volume 125,\n",
    "2018,\n",
    "Pages 617-623,\n",
    "ISSN 1877-0509,\n",
    "https://doi.org/10.1016/j.procs.2017.12.079.\n",
    "(https://www.sciencedirect.com/science/article/pii/S1877050917328478)\n",
    "Abstract: Smishing is a cyber-security attack, which utilizes Short Message Service (SMS) to steal personal credentials of mobile users. The trust level of users on their smart devices has attracted attackers for performing various mobile security attacks like Smishing. In this paper, we implement the rule-based data mining classification approach in the detection of smishing messages. The proposed approach identified nine rules which can efficiently filter smishing SMS from the genuine one. Further, our approach applies rule-based classification algorithms to train these outstanding rules. Since the SMS text messages are very short and generally written in Lingo language, we have used text normalization to convert them into standard form to obtain better rules. The performance of the proposed approach is evaluated, and it achieved more than 99% true negative rate. Furthermore, the proposed approach is very efficient for the detection of the zero hour attack too.\n",
    "Keywords: Smishing; Mobile Phishing; Data mining; Short messaging service; Machine learning\n",
    "\n",
    "> Reprodução de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71268bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import ruleset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75896f",
   "metadata": {},
   "source": [
    "#### 1. Pré processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08546b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "53271d41-0530-4d62-804d-5cfe95f74368",
       "rows": [
        [
         "0",
         "ham",
         "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat..."
        ],
        [
         "1",
         "ham",
         "Ok lar... Joking wif u oni..."
        ],
        [
         "2",
         "spam",
         "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's"
        ],
        [
         "3",
         "ham",
         "U dun say so early hor... U c already then say..."
        ],
        [
         "4",
         "ham",
         "Nah I don't think he goes to usf, he lives around here though"
        ],
        [
         "5",
         "spam",
         "FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv"
        ],
        [
         "6",
         "ham",
         "Even my brother is not like to speak with me. They treat me like aids patent."
        ],
        [
         "7",
         "ham",
         "As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune"
        ],
        [
         "8",
         "spam",
         "WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only."
        ],
        [
         "9",
         "spam",
         "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030"
        ],
        [
         "10",
         "ham",
         "I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today."
        ],
        [
         "11",
         "spam",
         "SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info"
        ],
        [
         "12",
         "spam",
         "URGENT! You have won a 1 week FREE membership in our å£100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18"
        ],
        [
         "13",
         "ham",
         "I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times."
        ],
        [
         "14",
         "ham",
         "I HAVE A DATE ON SUNDAY WITH WILL!!"
        ],
        [
         "15",
         "spam",
         "XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL"
        ],
        [
         "16",
         "ham",
         "Oh k...i'm watching here:)"
        ],
        [
         "17",
         "ham",
         "Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet."
        ],
        [
         "18",
         "ham",
         "Fine if thatåÕs the way u feel. ThatåÕs the way its gota b"
        ],
        [
         "19",
         "spam",
         "England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/Ì¼1.20 POBOXox36504W45WQ 16+"
        ],
        [
         "20",
         "ham",
         "Is that seriously how you spell his name?"
        ],
        [
         "21",
         "ham",
         "IÛ÷m going to try for 2 months ha ha only joking"
        ],
        [
         "22",
         "ham",
         "So Ì_ pay first lar... Then when is da stock comin..."
        ],
        [
         "23",
         "ham",
         "Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already?"
        ],
        [
         "24",
         "ham",
         "Ffffffffff. Alright no way I can meet up with you sooner?"
        ],
        [
         "25",
         "ham",
         "Just forced myself to eat a slice. I'm really not hungry tho. This sucks. Mark is getting worried. He knows I'm sick when I turn down pizza. Lol"
        ],
        [
         "26",
         "ham",
         "Lol your always so convincing."
        ],
        [
         "27",
         "ham",
         "Did you catch the bus ? Are you frying an egg ? Did you make a tea? Are you eating your mom's left over dinner ? Do you feel my Love ?"
        ],
        [
         "28",
         "ham",
         "I'm back &amp; we're packing the car now, I'll let you know if there's room"
        ],
        [
         "29",
         "ham",
         "Ahhh. Work. I vaguely remember that! What does it feel like? Lol"
        ],
        [
         "30",
         "ham",
         "Wait that's still not all that clear, were you not sure about me being sarcastic or that that's why x doesn't want to live with us"
        ],
        [
         "31",
         "ham",
         "Yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and he got caught up in that. Till 2! But we won't go there! Not doing too badly cheers. You? "
        ],
        [
         "32",
         "ham",
         "K tell me anything about you."
        ],
        [
         "33",
         "ham",
         "For fear of fainting with the of all that housework you just did? Quick have a cuppa"
        ],
        [
         "34",
         "spam",
         "Thanks for your subscription to Ringtone UK your mobile will be charged å£5/month Please confirm by replying YES or NO. If you reply NO you will not be charged"
        ],
        [
         "35",
         "ham",
         "Yup... Ok i go home look at the timings then i msg Ì_ again... Xuhui going to learn on 2nd may too but her lesson is at 8am"
        ],
        [
         "36",
         "ham",
         "Oops, I'll let you know when my roommate's done"
        ],
        [
         "37",
         "ham",
         "I see the letter B on my car"
        ],
        [
         "38",
         "ham",
         "Anything lor... U decide..."
        ],
        [
         "39",
         "ham",
         "Hello! How's you and how did saturday go? I was just texting to see if you'd decided to do anything tomo. Not that i'm trying to invite myself or anything!"
        ],
        [
         "40",
         "ham",
         "Pls go ahead with watts. I just wanted to be sure. Do have a great weekend. Abiola"
        ],
        [
         "41",
         "ham",
         "Did I forget to tell you ? I want you , I need you, I crave you ... But most of all ... I love you my sweet Arabian steed ... Mmmmmm ... Yummy"
        ],
        [
         "42",
         "spam",
         "07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow"
        ],
        [
         "43",
         "ham",
         "WHO ARE YOU SEEING?"
        ],
        [
         "44",
         "ham",
         "Great! I hope you like your man well endowed. I am  &lt;#&gt;  inches..."
        ],
        [
         "45",
         "ham",
         "No calls..messages..missed calls"
        ],
        [
         "46",
         "ham",
         "Didn't you get hep b immunisation in nigeria."
        ],
        [
         "47",
         "ham",
         "Fair enough, anything going on?"
        ],
        [
         "48",
         "ham",
         "Yeah hopefully, if tyler can't do it I could maybe ask around a bit"
        ],
        [
         "49",
         "ham",
         "U don't know how stubborn I am. I didn't even want to go to the hospital. I kept telling Mark I'm not a weak sucker. Hospitals are for weak suckers."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5572
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the CSV dataset as a dataframe\n",
    "# Since pandas is already imported in cell 1, we can use it directly\n",
    "df = pd.read_csv('SMSSpamCollectionDataset.csv', encoding='latin-1')\n",
    "df = df[['label', 'text']]\n",
    "\n",
    "# Display the first few rows to get a glimpse of the data\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "299f844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005!\n",
      "Normalizado: free entry wkly comp win cup final tkts 21st may 2005 !\n"
     ]
    }
   ],
   "source": [
    "# Download dos recursos necessários do NLTK\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True) \n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "def normalize_text(original_text) -> str:\n",
    "    '''\n",
    "    Recebe um SMS\n",
    "    \n",
    "    Retorna texto original normalizado (mais conservador para melhor performance)\n",
    "    '''\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = original_text.lower()\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Tokenize (método mais simples se houver problemas com punkt)\n",
    "    try:\n",
    "        words = nltk.word_tokenize(text)\n",
    "    except:\n",
    "        # Fallback para tokenização simples\n",
    "        words = text.split()\n",
    "    \n",
    "    # Remove stopwords apenas as mais comuns (mais conservador)\n",
    "    # IMPORTANTE: Preservar símbolos financeiros e matemáticos mesmo que sejam curtos\n",
    "    common_stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should'}\n",
    "    \n",
    "    # Símbolos financeiros e matemáticos importantes para detecção de spam/smishing\n",
    "    important_symbols = {\n",
    "        # Símbolos financeiros\n",
    "        '$', '£', '€', '¥', '₹', '¢', \n",
    "        # Símbolos matemáticos\n",
    "        '+', '-', '*', '/', '=', '<', '>', '≤', '≥', '≠', '±', '×', '÷',\n",
    "        # Outros símbolos importantes  \n",
    "        '%', '#', '@', '&', '!', '?'\n",
    "    }\n",
    "    \n",
    "    # Manter palavra se: não é stopword E (tem mais de 1 char OU é símbolo importante)\n",
    "    words = [word for word in words if word not in common_stopwords and (len(word) > 1 or word in important_symbols)]\n",
    "    \n",
    "    # NÃO aplicar stemming agressivo - manter palavras mais íntegras\n",
    "    # Preservar símbolos importantes e palavras relevantes\n",
    "    words = [word for word in words if len(word) > 2 or word in important_symbols]\n",
    "    \n",
    "    # Join words back into a string\n",
    "    normalized_text = ' '.join(words)\n",
    "    \n",
    "    return normalized_text\n",
    "\n",
    "# Testar com um exemplo\n",
    "sample_text = \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005!\"\n",
    "print(f\"Original: {sample_text}\")\n",
    "print(f\"Normalizado: {normalize_text(sample_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0678b",
   "metadata": {},
   "source": [
    "(debugando o por quê do símbolo de dolar estar sumindo e verificando que ainda funciona...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e9e8ff",
   "metadata": {},
   "source": [
    "### Balanceando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e95eceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "62e79eb0-29c0-45a4-a4b3-c4942db91dd2",
       "rows": [
        [
         "3714",
         "ham",
         "I am late,so call you tomorrow morning.take care sweet dreams....u and me...ummifying...bye."
        ],
        [
         "1311",
         "ham",
         "U r too much close to my heart. If u go away i will be shattered. Plz stay with me."
        ],
        [
         "548",
         "ham",
         "Wait  &lt;#&gt;  min.."
        ],
        [
         "1324",
         "ham",
         "Can you call me plz. Your number shows out of coveragd area. I have urgnt call in vasai &amp; have to reach before 4'o clock so call me plz"
        ],
        [
         "3184",
         "ham",
         "MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOULDN'T BE A PROBLEM."
        ],
        [
         "1075",
         "ham",
         "Oi. Ami parchi na re. Kicchu kaaj korte iccha korche na. Phone ta tul na. Plz. Plz."
        ],
        [
         "1412",
         "ham",
         "Wen ur lovable bcums angry wid u, dnt take it seriously.. Coz being angry is d most childish n true way of showing deep affection, care n luv!.. kettoda manda... Have nice day da."
        ],
        [
         "3043",
         "ham",
         "Let me know how it changes in the next 6hrs. It can even be appendix but you are out of that age range. However its not impossible. So just chill and let me know in 6hrs"
        ],
        [
         "14",
         "ham",
         "I HAVE A DATE ON SUNDAY WITH WILL!!"
        ],
        [
         "5097",
         "ham",
         "Sorry about that this is my mates phone and i didnt write it love Kate"
        ],
        [
         "3484",
         "ham",
         "No:-)i got rumour that you going to buy apartment in chennai:-)"
        ],
        [
         "2209",
         "ham",
         "Hmm well, night night "
        ],
        [
         "4454",
         "ham",
         "Storming msg: Wen u lift d phne, u say \\HELLO\\\" Do u knw wt is d real meaning of HELLO?? . . . It's d name of a girl..! . . . Yes.. And u knw who is dat girl?? \\\"Margaret Hello\\\" She is d girlfrnd f Grahmbell who invnted telphone... . . . . Moral:One can 4get d name of a person"
        ],
        [
         "3942",
         "ham",
         "I got a call from a landline number. . . I am asked to come to anna nagar . . . I will go in the afternoon"
        ],
        [
         "5108",
         "ham",
         "The sign of maturity is not when we start saying big things.. But actually it is, when we start understanding small things... *HAVE A NICE EVENING* BSLVYL"
        ],
        [
         "955",
         "ham",
         "Sorry i now then c ur msg... Yar lor so poor thing... But only 4 one night... Tmr u'll have a brand new room 2 sleep in..."
        ],
        [
         "2488",
         "ham",
         "Aiyah e rain like quite big leh. If drizzling i can at least run home."
        ],
        [
         "1389",
         "ham",
         "Haha... Where got so fast lose weight, thk muz go 4 a month den got effect... Gee,later we go aust put bk e weight."
        ],
        [
         "1998",
         "ham",
         "Well, I have to leave for my class babe ... You never came back to me ... :-( ... Hope you have a nice sleep, my love"
        ],
        [
         "1355",
         "ham",
         "Convey my regards to him"
        ],
        [
         "979",
         "ham",
         "Another month. I need chocolate weed and alcohol."
        ],
        [
         "5092",
         "ham",
         "My fri ah... Okie lor,goin 4 my drivin den go shoppin after tt..."
        ],
        [
         "1878",
         "ham",
         "I AM AT A PARTY WITH ALEX NICHOLS"
        ],
        [
         "3181",
         "ham",
         "My Parents, My Kidz, My Friends n My Colleagues. All screaming.. SURPRISE !! and I was waiting on the sofa.. ... ..... ' NAKED...!"
        ],
        [
         "2955",
         "ham",
         "Yes there were many sweets"
        ],
        [
         "5070",
         "ham",
         "As in different styles?"
        ],
        [
         "4382",
         "ham",
         "No need lar i go engin? Cos my sis at arts today..."
        ],
        [
         "4440",
         "ham",
         "I'm going 2 orchard now laready me reaching soon. U reaching?"
        ],
        [
         "5119",
         "ham",
         "Lol for real. She told my dad I have cancer"
        ],
        [
         "31",
         "ham",
         "Yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and he got caught up in that. Till 2! But we won't go there! Not doing too badly cheers. You? "
        ],
        [
         "3928",
         "ham",
         "Yes. Nigh you cant aha."
        ],
        [
         "1218",
         "ham",
         "K..k..i'm also fine:)when will you complete the course?"
        ],
        [
         "5533",
         "ham",
         "Hey chief, can you give me a bell when you get this. Need to talk to you about this royal visit on the 1st june. "
        ],
        [
         "1138",
         "ham",
         "What * u wearing?"
        ],
        [
         "5553",
         "ham",
         "Hahaha..use your brain dear"
        ],
        [
         "1787",
         "ham",
         "Yes:)sura in sun tv.:)lol."
        ],
        [
         "2837",
         "ham",
         "Were trying to find a Chinese food place around here"
        ],
        [
         "2911",
         "ham",
         "You didn't have to tell me that...now i'm thinking. Plus he's going to stop all your runs"
        ],
        [
         "3880",
         "ham",
         "Can you plz tell me the ans. BSLVYL sent via fullonsms.com"
        ],
        [
         "4864",
         "ham",
         "I'm really sorry I lit your hair on fire"
        ],
        [
         "2509",
         "ham",
         "U wake up already? Wat u doing? U picking us up later rite? I'm taking sq825, reaching ard 7 smth 8 like dat. U can check e arrival time. C ya soon..."
        ],
        [
         "3462",
         "ham",
         "i am seeking a lady in the street and a freak in the sheets. Is that you?"
        ],
        [
         "4105",
         "ham",
         "K then 2marrow are you coming to class."
        ],
        [
         "5273",
         "ham",
         "Its too late:)but its k.wish you the same."
        ],
        [
         "5548",
         "ham",
         "No, I was trying it all weekend ;V"
        ],
        [
         "3146",
         "ham",
         "Oh thats late! Well have a good night and i will give u a call tomorrow. Iam now going to go to sleep night night"
        ],
        [
         "175",
         "ham",
         "Let me know when you've got the money so carlos can make the call"
        ],
        [
         "3831",
         "ham",
         "Ok."
        ],
        [
         "121",
         "ham",
         "here is my new address -apples&pairs&all that malarky"
        ],
        [
         "2062",
         "ham",
         "Is there any training tomorrow?"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1494
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>ham</td>\n",
       "      <td>I am late,so call you tomorrow morning.take ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>ham</td>\n",
       "      <td>U r too much close to my heart. If u go away i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wait  &amp;lt;#&amp;gt;  min..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can you call me plz. Your number shows out of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>ham</td>\n",
       "      <td>MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>spam</td>\n",
       "      <td>+123 Congratulations - in this week's competit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi. Customer Loyalty Offer:The NEW Nokia6650 M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>spam</td>\n",
       "      <td>Call from 08702490080 - tells u 2 call 0906635...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>spam</td>\n",
       "      <td>Ur cash-balance is currently 500 pounds - to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>spam</td>\n",
       "      <td>08714712388 between 10am-7pm Cost 10p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "3714   ham  I am late,so call you tomorrow morning.take ca...\n",
       "1311   ham  U r too much close to my heart. If u go away i...\n",
       "548    ham                             Wait  &lt;#&gt;  min..\n",
       "1324   ham  Can you call me plz. Your number shows out of ...\n",
       "3184   ham  MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOU...\n",
       "...    ...                                                ...\n",
       "504   spam  +123 Congratulations - in this week's competit...\n",
       "737   spam  Hi. Customer Loyalty Offer:The NEW Nokia6650 M...\n",
       "1928  spam  Call from 08702490080 - tells u 2 call 0906635...\n",
       "3228  spam  Ur cash-balance is currently 500 pounds - to m...\n",
       "712   spam              08714712388 between 10am-7pm Cost 10p\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ham = df[df[\"label\"] == \"ham\"]\n",
    "df_spam = df[df[\"label\"] == \"spam\"]\n",
    "\n",
    "min_len = min(len(df_ham), len(df_spam))\n",
    "\n",
    "\n",
    "df_ham_sample = df_ham.sample(n=min_len, random_state=42)\n",
    "df_spam_sample = df_spam.sample(n=min_len, random_state=42)\n",
    "\n",
    "big_df = df\n",
    "df = pd.concat([df_ham_sample,df_spam_sample])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4e3cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  \\\n",
      "3714  I am late,so call you tomorrow morning.take ca...   \n",
      "1311  U r too much close to my heart. If u go away i...   \n",
      "548                              Wait  &lt;#&gt;  min..   \n",
      "1324  Can you call me plz. Your number shows out of ...   \n",
      "3184  MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOU...   \n",
      "\n",
      "                                        normalized_text  \n",
      "3714  late call you tomorrow morning.take care sweet...  \n",
      "1311       too much close heart away shattered plz stay  \n",
      "548                                      wait & # & min  \n",
      "1324  can you call plz your number shows out coverag...  \n",
      "3184     maybe you woke before fucking this n't problem  \n"
     ]
    }
   ],
   "source": [
    "# Apply the normalize_text function to the text column\n",
    "df['normalized_text'] = df['text'].apply(normalize_text)\n",
    "\n",
    "# Display the first few rows to see the normalized text\n",
    "print(df[['text', 'normalized_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae67821",
   "metadata": {},
   "source": [
    "### 2. Extração de features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101118a4",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after adding rule columns: (1494, 18)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "normalized_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rule1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule5",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule7",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule8",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule9",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule10",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule11",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule12",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule13",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule14",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rule15",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f752565f-db93-4dab-a767-a8836b495136",
       "rows": [
        [
         "3714",
         "ham",
         "I am late,so call you tomorrow morning.take care sweet dreams....u and me...ummifying...bye.",
         "late call you tomorrow morning.take care sweet dreams .... ... ummifying ... bye",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         null
        ],
        [
         "1311",
         "ham",
         "U r too much close to my heart. If u go away i will be shattered. Plz stay with me.",
         "too much close heart away shattered plz stay",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null
        ],
        [
         "548",
         "ham",
         "Wait  &lt;#&gt;  min..",
         "wait & # & min",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null
        ],
        [
         "1324",
         "ham",
         "Can you call me plz. Your number shows out of coveragd area. I have urgnt call in vasai &amp; have to reach before 4'o clock so call me plz",
         "can you call plz your number shows out coveragd area urgnt call vasai & amp reach before clock call plz",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         null
        ],
        [
         "3184",
         "ham",
         "MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOULDN'T BE A PROBLEM.",
         "maybe you woke before fucking this n't problem",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         null
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>rule1</th>\n",
       "      <th>rule2</th>\n",
       "      <th>rule3</th>\n",
       "      <th>rule4</th>\n",
       "      <th>rule5</th>\n",
       "      <th>rule6</th>\n",
       "      <th>rule7</th>\n",
       "      <th>rule8</th>\n",
       "      <th>rule9</th>\n",
       "      <th>rule10</th>\n",
       "      <th>rule11</th>\n",
       "      <th>rule12</th>\n",
       "      <th>rule13</th>\n",
       "      <th>rule14</th>\n",
       "      <th>rule15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>ham</td>\n",
       "      <td>I am late,so call you tomorrow morning.take ca...</td>\n",
       "      <td>late call you tomorrow morning.take care sweet...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>ham</td>\n",
       "      <td>U r too much close to my heart. If u go away i...</td>\n",
       "      <td>too much close heart away shattered plz stay</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wait  &amp;lt;#&amp;gt;  min..</td>\n",
       "      <td>wait &amp; # &amp; min</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can you call me plz. Your number shows out of ...</td>\n",
       "      <td>can you call plz your number shows out coverag...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>ham</td>\n",
       "      <td>MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOU...</td>\n",
       "      <td>maybe you woke before fucking this n't problem</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "3714   ham  I am late,so call you tomorrow morning.take ca...   \n",
       "1311   ham  U r too much close to my heart. If u go away i...   \n",
       "548    ham                             Wait  &lt;#&gt;  min..   \n",
       "1324   ham  Can you call me plz. Your number shows out of ...   \n",
       "3184   ham  MAYBE IF YOU WOKE UP BEFORE FUCKING 3 THIS WOU...   \n",
       "\n",
       "                                        normalized_text  rule1  rule2  rule3  \\\n",
       "3714  late call you tomorrow morning.take care sweet...      1      0      0   \n",
       "1311       too much close heart away shattered plz stay      0      0      0   \n",
       "548                                      wait & # & min      0      0      0   \n",
       "1324  can you call plz your number shows out coverag...      0      0      0   \n",
       "3184     maybe you woke before fucking this n't problem      0      0      0   \n",
       "\n",
       "      rule4  rule5  rule6  rule7  rule8  rule9  rule10  rule11  rule12  \\\n",
       "3714      0      0      0      0      1      0       1       0       0   \n",
       "1311      0      0      0      0      0      0       0       0       0   \n",
       "548       0      0      0      0      0      0       0       0       0   \n",
       "1324      0      0      0      0      0      0       0       0       0   \n",
       "3184      0      0      0      0      0      0       0       0       0   \n",
       "\n",
       "      rule13  rule14  rule15  \n",
       "3714       1       0     NaN  \n",
       "1311       0       0     NaN  \n",
       "548        0       0     NaN  \n",
       "1324       1       0     NaN  \n",
       "3184       0       1     NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply each rule function from the ruleset module to create new columns\n",
    "df['rule1'] = df['normalized_text'].apply(ruleset.rule1)\n",
    "df['rule2'] = df['normalized_text'].apply(ruleset.rule2)\n",
    "df['rule3'] = df['normalized_text'].apply(ruleset.rule3)\n",
    "df['rule4'] = df['normalized_text'].apply(ruleset.rule4)\n",
    "df['rule5'] = df['normalized_text'].apply(ruleset.rule5)\n",
    "df['rule6'] = df['normalized_text'].apply(ruleset.rule6)\n",
    "df['rule7'] = df['normalized_text'].apply(ruleset.rule7)\n",
    "df['rule8'] = df['normalized_text'].apply(ruleset.rule8)\n",
    "df['rule9'] = df['normalized_text'].apply(ruleset.rule9)\n",
    "\n",
    "df['rule10'] = df['normalized_text'].apply(ruleset.rule10)\n",
    "df['rule11'] = df['normalized_text'].apply(ruleset.rule11)\n",
    "df['rule12'] = df['normalized_text'].apply(ruleset.rule12)\n",
    "df['rule13'] = df['normalized_text'].apply(ruleset.rule13)\n",
    "df['rule14'] = df['normalized_text'].apply(ruleset.rule14)\n",
    "df['rule15'] = df['normalized_text'].apply(ruleset.rule15)\n",
    "\n",
    "# Display the dataframe with all rule columns\n",
    "print(\"Shape after adding rule columns:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfb4334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Results:\n",
      "Accuracy: 91.97%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       150\n",
      "           1       0.96      0.87      0.92       149\n",
      "\n",
      "    accuracy                           0.92       299\n",
      "   macro avg       0.92      0.92      0.92       299\n",
      "weighted avg       0.92      0.92      0.92       299\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[145   5]\n",
      " [ 19 130]]\n",
      "\n",
      "True Negative Rate: 96.67%\n",
      "True Positive Rate (Sensitivity/Recall): 87.25%\n",
      "False Positive Rate: 3.33%\n",
      "False Negative Rate: 12.75%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Remove the problematic environment variable\n",
    "if 'MPLBACKEND' in os.environ:\n",
    "    del os.environ['MPLBACKEND']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Convert labels to binary values (ham=0, spam=1)\n",
    "df['binary_label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "features = ['rule1', 'rule2', 'rule3', 'rule4', 'rule5', 'rule6', 'rule7', 'rule8', 'rule9', 'rule10', 'rule11', 'rule12', 'rule13', 'rule14', 'rule15']\n",
    "\n",
    "# Extract features (all rule columns) and target variable\n",
    "X = df[features].dropna(axis=1)  # Drop rows with NaN values in features\n",
    "y = df['binary_label']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Create and train a Decision Tree Classifier\n",
    "# dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dt_classifier = LogisticRegression(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Decision Tree Classifier Results:\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate feature importances\n",
    "# feature_importances = dt_classifier.feature_importances_\n",
    "# feature_names = X.columns\n",
    "# importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "# importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# print(\"\\nFeature Importance:\")\n",
    "# print(importance_df)\n",
    "\n",
    "# Print true negative rate as mentioned in the paper\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "tnr = tn / (tn + fp)\n",
    "print(f\"\\nTrue Negative Rate: {tnr * 100:.2f}%\")\n",
    "print(f\"True Positive Rate (Sensitivity/Recall): {tp / (tp + fn) * 100:.2f}%\")\n",
    "print(f\"False Positive Rate: {fp / (fp + tn) * 100:.2f}%\")\n",
    "print(f\"False Negative Rate: {fn / (fn + tp) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08db32a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       597\n",
      "           1       0.95      0.89      0.92       598\n",
      "\n",
      "    accuracy                           0.92      1195\n",
      "   macro avg       0.93      0.92      0.92      1195\n",
      "weighted avg       0.93      0.92      0.92      1195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics of traing test\n",
    "print(classification_report(y_train, dt_classifier.predict(X_train)))\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "241c2064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISE DE OVERFITTING ===\n",
      "\n",
      "Validação Cruzada (5-fold):\n",
      "Scores: [0.94067797 0.94545455 0.93965517 0.95454545 0.90265487]\n",
      "Média: 0.9366 (+/- 0.0355)\n",
      "Desvio padrão: 0.0178\n",
      "✅ Desvio padrão baixo - modelo parece estável\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "## Análise de Overfitting\n",
    "\n",
    "# Vamos usar validação cruzada para verificar se há overfitting\n",
    "from sklearn.model_selection import cross_val_score, validation_curve, learning_curve\n",
    "import numpy as np\n",
    "\n",
    "# 1. Validação Cruzada com 5 folds\n",
    "print(\"=== ANÁLISE DE OVERFITTING ===\\n\")\n",
    "\n",
    "# Validação cruzada\n",
    "cv_scores = cross_val_score(dt_classifier, X_train, y_train, cv=5, scoring='precision')\n",
    "print(f\"Validação Cruzada (5-fold):\")\n",
    "print(f\"Scores: {cv_scores}\")\n",
    "print(f\"Média: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "print(f\"Desvio padrão: {cv_scores.std():.4f}\")\n",
    "\n",
    "# Se o desvio padrão for muito alto, pode indicar overfitting\n",
    "if cv_scores.std() > 0.02:\n",
    "    print(\"⚠️  ALERTA: Alto desvio padrão pode indicar overfitting!\")\n",
    "else:\n",
    "    print(\"✅ Desvio padrão baixo - modelo parece estável\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d1b00e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANÁLISE DAS FEATURES ===\n",
      "Distribuição das regras (quantos SMS triggeram cada regra):\n",
      "rule1: 184.0/1494 (12.3%)\n",
      "rule2: 442.0/1494 (29.6%)\n",
      "rule3: 291.0/1494 (19.5%)\n",
      "rule4: 290.0/1494 (19.4%)\n",
      "rule5: 432.0/1494 (28.9%)\n",
      "rule6: 40.0/1494 (2.7%)\n",
      "rule7: 106.0/1494 (7.1%)\n",
      "rule8: 640.0/1494 (42.8%)\n",
      "rule9: 0.0/1494 (0.0%)\n",
      "rule10: 369.0/1494 (24.7%)\n",
      "rule11: 50.0/1494 (3.3%)\n",
      "rule12: 33.0/1494 (2.2%)\n",
      "rule13: 498.0/1494 (33.3%)\n",
      "rule14: 195.0/1494 (13.1%)\n",
      "rule15: 122.0/1494 (8.2%)\n",
      "\n",
      "SMS que não triggeram NENHUMA regra: 426\n",
      "Destes, quantos são spam: 15\n",
      "Destes, quantos são ham: 411\n",
      "\n",
      "Correlações mais altas entre regras:\n",
      "rule2 vs rule5: 0.324\n",
      "rule2 vs rule8: 0.334\n",
      "rule3 vs rule4: 0.331\n",
      "rule3 vs rule5: 0.488\n",
      "rule3 vs rule8: 0.507\n",
      "rule3 vs rule14: 0.301\n",
      "rule4 vs rule8: 0.314\n",
      "rule4 vs rule13: 0.418\n",
      "rule5 vs rule8: 0.382\n",
      "rule5 vs rule13: 0.332\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 2. Análise da Distribuição das Features\n",
    "print(\"\\n=== ANÁLISE DAS FEATURES ===\")\n",
    "\n",
    "features = ['rule1', 'rule2', 'rule3', 'rule4', 'rule5', 'rule6', 'rule7', 'rule8', 'rule9', 'rule10', 'rule11', 'rule12', 'rule13', 'rule14', 'rule15']\n",
    "\n",
    "# Verificar distribuição das regras\n",
    "feature_distribution = df[features].sum()\n",
    "total_samples = len(df)\n",
    "\n",
    "print(\"Distribuição das regras (quantos SMS triggeram cada regra):\")\n",
    "for rule, count in feature_distribution.items():\n",
    "    percentage = (count / total_samples) * 100\n",
    "    print(f\"{rule}: {count}/{total_samples} ({percentage:.1f}%)\")\n",
    "\n",
    "# Verificar quantos SMS não triggeraram nenhuma regra\n",
    "no_rules_triggered = df[(df[features].sum(axis=1) == 0)]\n",
    "print(f\"\\nSMS que não triggeram NENHUMA regra: {len(no_rules_triggered)}\")\n",
    "print(f\"Destes, quantos são spam: {len(no_rules_triggered[no_rules_triggered['label'] == 'spam'])}\")\n",
    "print(f\"Destes, quantos são ham: {len(no_rules_triggered[no_rules_triggered['label'] == 'ham'])}\")\n",
    "\n",
    "# Verificar correlação entre regras\n",
    "correlation_matrix = df[features].corr()\n",
    "print(f\"\\nCorrelações mais altas entre regras:\")\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > 0.3:  # Correlação moderada ou alta\n",
    "            print(f\"{correlation_matrix.columns[i]} vs {correlation_matrix.columns[j]}: {corr_value:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985dec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANÁLISE DETALHADA DA RULE4 ===\n",
      "Distribuição Rule4 vs Label:\n",
      "label  ham  spam\n",
      "rule4           \n",
      "0      747   457\n",
      "1        0   290\n",
      "\n",
      "Se usássemos APENAS a Rule4:\n",
      "Acurácia: 0.6941 (69.41%)\n",
      "\n",
      "Rule4 detecta 290/747 spam (38.8%)\n",
      "Rule4 é triggerrada por 0/747 ham (0.0%)\n",
      "⚠️  Rule4 pode estar sendo muito específica para spam!\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 3. Análise específica da Rule4 (dominante)\n",
    "print(\"\\n=== ANÁLISE DETALHADA DA RULE4 ===\")\n",
    "\n",
    "# Analisar a performance da rule4 sozinha\n",
    "rule4_analysis = df.groupby(['rule4', 'label']).size().unstack(fill_value=0)\n",
    "print(\"Distribuição Rule4 vs Label:\")\n",
    "print(rule4_analysis)\n",
    "\n",
    "# Calcular métricas se usássemos apenas a rule4\n",
    "rule4_only_accuracy = ((rule4_analysis.loc[0, 'ham'] + rule4_analysis.loc[1, 'spam']) / len(df))\n",
    "print(f\"\\nSe usássemos APENAS a Rule4:\")\n",
    "print(f\"Acurácia: {rule4_only_accuracy:.4f} ({rule4_only_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Verificar quantos spam/ham triggeraram rule4\n",
    "spam_with_rule4 = len(df[(df['label'] == 'spam') & (df['rule4'] == 1)])\n",
    "total_spam = len(df[df['label'] == 'spam'])\n",
    "ham_with_rule4 = len(df[(df['label'] == 'ham') & (df['rule4'] == 1)])\n",
    "total_ham = len(df[df['label'] == 'ham'])\n",
    "\n",
    "print(f\"\\nRule4 detecta {spam_with_rule4}/{total_spam} spam ({spam_with_rule4/total_spam*100:.1f}%)\")\n",
    "print(f\"Rule4 é triggerrada por {ham_with_rule4}/{total_ham} ham ({ham_with_rule4/total_ham*100:.1f}%)\")\n",
    "\n",
    "# Isso mostra se a rule4 é muito específica\n",
    "if ham_with_rule4/total_ham < 0.02:  # Menos de 2% dos ham triggeram rule4\n",
    "    print(\"⚠️  Rule4 pode estar sendo muito específica para spam!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c8df901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TESTE SEM RULE4 ===\n",
      "Acurácia SEM Rule4: 0.9231 (92.31%)\n",
      "Queda de performance: -0.33 pontos percentuais\n",
      "\n",
      "Nova distribuição de importância (sem rule4):\n",
      "rule5: 0.405\n",
      "rule13: 0.243\n",
      "rule3: 0.100\n",
      "rule2: 0.070\n",
      "rule8: 0.061\n",
      "rule1: 0.044\n",
      "rule10: 0.026\n",
      "rule7: 0.023\n",
      "rule14: 0.010\n",
      "rule6: 0.009\n",
      "rule11: 0.004\n",
      "rule12: 0.004\n",
      "rule9: 0.000\n",
      "rule15: 0.000\n",
      "\n",
      "Validação cruzada sem rule4: 0.8963 (+/- 0.0234)\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 4. Teste sem a Rule4 dominante\n",
    "print(\"\\n=== TESTE SEM RULE4 ===\")\n",
    "\n",
    "# Treinar modelo sem a rule4\n",
    "X_without_rule4 = df[['rule1', 'rule2', 'rule3', 'rule5', 'rule6', 'rule7', 'rule8', 'rule9', 'rule10', 'rule11', 'rule12', 'rule13', 'rule14', 'rule15']]\n",
    "y = df['binary_label']\n",
    "\n",
    "# Split dos dados\n",
    "X_train_no4, X_test_no4, y_train_no4, y_test_no4 = train_test_split(\n",
    "    X_without_rule4, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Treinar novo modelo\n",
    "dt_no_rule4 = DecisionTreeClassifier(random_state=42)\n",
    "dt_no_rule4.fit(X_train_no4, y_train_no4)\n",
    "\n",
    "# Fazer predições\n",
    "y_pred_no4 = dt_no_rule4.predict(X_test_no4)\n",
    "accuracy_no4 = accuracy_score(y_test_no4, y_pred_no4)\n",
    "\n",
    "print(f\"Acurácia SEM Rule4: {accuracy_no4:.4f} ({accuracy_no4*100:.2f}%)\")\n",
    "print(f\"Queda de performance: {(accuracy - accuracy_no4)*100:.2f} pontos percentuais\")\n",
    "\n",
    "# Feature importance sem rule4\n",
    "feature_imp_no4 = dt_no_rule4.feature_importances_\n",
    "feature_names_no4 = X_without_rule4.columns\n",
    "importance_df_no4 = pd.DataFrame({'Feature': feature_names_no4, 'Importance': feature_imp_no4})\n",
    "importance_df_no4 = importance_df_no4.sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nNova distribuição de importância (sem rule4):\")\n",
    "for idx, row in importance_df_no4.iterrows():\n",
    "    print(f\"{row['Feature']}: {row['Importance']:.3f}\")\n",
    "\n",
    "# Validação cruzada sem rule4\n",
    "cv_scores_no4 = cross_val_score(dt_no_rule4, X_without_rule4, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\nValidação cruzada sem rule4: {cv_scores_no4.mean():.4f} (+/- {cv_scores_no4.std() * 2:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fef097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. Conclusões sobre Overfitting - ANÁLISE FINAL ATUALIZADA COM DADOS CORRETOS\n",
    "# print(\"\\n=== CONCLUSÕES SOBRE OVERFITTING (DATASET BALANCEADO) ===\")\n",
    "\n",
    "# # Dados corretos das análises executadas\n",
    "# cv_mean = cv_scores.mean()\n",
    "# cv_std = cv_scores.std()\n",
    "# no_rules_count = len(no_rules_triggered)\n",
    "# no_rules_spam = len(no_rules_triggered[no_rules_triggered['label'] == 'spam'])\n",
    "# no_rules_ham = len(no_rules_triggered[no_rules_triggered['label'] == 'ham'])\n",
    "\n",
    "# # Importâncias das features principais\n",
    "# rule4_importance = importance_df[importance_df['Feature'] == 'rule4']['Importance'].iloc[0]\n",
    "# rule5_importance = importance_df[importance_df['Feature'] == 'rule5']['Importance'].iloc[0]\n",
    "# rule9_count = feature_distribution['rule9']\n",
    "\n",
    "# print(\"✅ EVIDÊNCIAS CONTRA OVERFITTING CLÁSSICO:\")\n",
    "# print(f\"• Validação cruzada ESTÁVEL: {cv_mean:.4f} (±{cv_std:.4f}) - Desvio baixo = {cv_std*100:.2f}%\")\n",
    "# print(f\"• Modelo sem rule4 mantém {accuracy_no4*100:.2f}% de acurácia (perda de apenas {(accuracy - accuracy_no4)*100:.2f}pp)\")\n",
    "# print(f\"• Cross-validation sem rule4: {cv_scores_no4.mean():.4f} - também estável\")\n",
    "# print(f\"• Dataset PERFEITAMENTE balanceado: {total_spam} spam vs {total_ham} ham\")\n",
    "# print(f\"• {no_rules_count} SMS não triggeram nenhuma regra ({no_rules_ham} ham, {no_rules_spam} spam)\")\n",
    "\n",
    "# print(\"\\n📊 NOVA DISTRIBUIÇÃO DE IMPORTÂNCIA (DADOS ATUALIZADOS):\")\n",
    "# print(f\"• Rule5 (palavras suspeitas): {rule5_importance*100:.1f}% - AGORA É A DOMINANTE!\")\n",
    "# print(f\"• Rule4 (números telefone): {rule4_importance*100:.1f}% - perdeu dominância\")\n",
    "# print(f\"• Rule2 (símbolos matemáticos): {importance_df[importance_df['Feature'] == 'rule2']['Importance'].iloc[0]*100:.1f}%\")\n",
    "# print(f\"• Rule3 (símbolos financeiros): {importance_df[importance_df['Feature'] == 'rule3']['Importance'].iloc[0]*100:.1f}%\")\n",
    "# print(f\"• Rule13: {importance_df[importance_df['Feature'] == 'rule13']['Importance'].iloc[0]*100:.1f}%\")\n",
    "\n",
    "# print(\"\\n🔍 ANÁLISE ESPECÍFICA DA RULE4 (NÚMEROS DE TELEFONE):\")\n",
    "# print(f\"• Rule4 detecta {spam_with_rule4}/{total_spam} spam ({spam_with_rule4/total_spam*100:.1f}%)\")\n",
    "# print(f\"• Rule4 NÃO triggera em NENHUM ham (0/{total_ham} = {ham_with_rule4/total_ham*100:.1f}%)\")\n",
    "# print(f\"• Rule4 sozinha teria {rule4_only_accuracy*100:.2f}% de acurácia\")\n",
    "# print(f\"• Rule4 é MUITO ESPECÍFICA - zero falsos positivos!\")\n",
    "\n",
    "# print(\"\\n📈 DISTRIBUIÇÃO DAS REGRAS NO DATASET:\")\n",
    "# print(f\"• Rule8 (visual): {feature_distribution['rule8']}/1494 ({feature_distribution['rule8']/1494*100:.1f}%) - mais ativa\")\n",
    "# print(f\"• Rule13: {feature_distribution['rule13']}/1494 ({feature_distribution['rule13']/1494*100:.1f}%)\")\n",
    "# print(f\"• Rule2 (matemática): {feature_distribution['rule2']}/1494 ({feature_distribution['rule2']/1494*100:.1f}%)\")\n",
    "# print(f\"• Rule5 (suspeitas): {feature_distribution['rule5']}/1494 ({feature_distribution['rule5']/1494*100:.1f}%)\")\n",
    "# print(f\"• Rule4 (telefone): {feature_distribution['rule4']}/1494 ({feature_distribution['rule4']/1494*100:.1f}%)\")\n",
    "# print(f\"• Rule9 (email): {rule9_count}/1494 ({rule9_count/1494*100:.1f}%) - nunca triggera!\")\n",
    "\n",
    "# print(\"\\n🎯 MÉTRICAS DE PERFORMANCE FINAIS:\")\n",
    "# print(f\"• Acurácia geral: {accuracy*100:.2f}%\")\n",
    "# print(f\"• True Negative Rate (especificidade): {tnr*100:.2f}%\")\n",
    "# print(f\"• True Positive Rate (sensibilidade): {tp/(tp+fn)*100:.2f}%\")\n",
    "# print(f\"• Precisão: {tp/(tp+fp)*100:.2f}%\")\n",
    "# print(f\"• F1-Score: {2*tp/(2*tp+fp+fn)*100:.2f}%\")\n",
    "# print(f\"• False Positive Rate: {fp/(fp+tn)*100:.2f}%\")\n",
    "# print(f\"• False Negative Rate: {fn/(fn+tp)*100:.2f}%\")\n",
    "\n",
    "# print(\"\\n\udd17 CORRELAÇÕES ENTRE REGRAS:\")\n",
    "# high_corr_found = False\n",
    "# for i in range(len(correlation_matrix.columns)):\n",
    "#     for j in range(i+1, len(correlation_matrix.columns)):\n",
    "#         corr_value = correlation_matrix.iloc[i, j]\n",
    "#         if abs(corr_value) > 0.4:  # Correlação alta\n",
    "#             print(f\"• {correlation_matrix.columns[i]} ↔ {correlation_matrix.columns[j]}: {corr_value:.3f}\")\n",
    "#             high_corr_found = True\n",
    "# if not high_corr_found:\n",
    "#     print(\"• Nenhuma correlação muito alta (>0.4) entre regras - boa independência\")\n",
    "\n",
    "# print(\"\\n🧠 INTERPRETAÇÃO FINAL:\")\n",
    "# print(\"• ✅ NÃO HÁ OVERFITTING - modelo generaliza bem (CV estável)\")\n",
    "# print(\"• ✅ Rule5 agora domina (37.4%) - melhor distribuição de importância\")\n",
    "# print(\"• ✅ Rule4 ainda importante (23.7%) mas não mais dominante\")\n",
    "# print(\"• ✅ Múltiplas regras contribuem significativamente\")\n",
    "# print(\"• ✅ Dataset balanceado eliminou viés anterior\")\n",
    "# print(\"• ⚠️  Rule9 (email) nunca triggera - pode ser removida ou melhorada\")\n",
    "# print(\"• ⚠️  426 SMS não triggeram nenhuma regra - oportunidade de melhoria\")\n",
    "\n",
    "# print(f\"\\n💡 RECOMENDAÇÕES ATUALIZADAS:\")\n",
    "# print(\"1. ✅ Modelo está saudável - sem overfitting clássico\")\n",
    "# print(\"2. 🔧 Investigar por que rule9 nunca triggera (0% de casos)\")\n",
    "# print(\"3. 🔧 Melhorar detecção dos 426 SMS que não triggeram regras\")\n",
    "# print(\"4. 🔧 Rules com baixa atividade: rule6 (2.7%), rule11 (3.3%), rule12 (2.2%)\")\n",
    "# print(\"5. 🎯 Considerar features adicionais para os 15 spam que não triggeram nenhuma regra\")\n",
    "# print(\"6. 📊 Manter dataset balanceado em futuros experimentos\")\n",
    "\n",
    "# print(f\"\\n🏆 VEREDICTO FINAL:\")\n",
    "# print(\"MODELO APROVADO - Sem evidências de overfitting!\")\n",
    "# print(\"Distribuição equilibrada de features, validação cruzada estável,\")\n",
    "# print(\"generalização adequada e métricas consistentes.\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
